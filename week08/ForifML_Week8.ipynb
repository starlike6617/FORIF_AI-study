{"cells":[{"cell_type":"markdown","metadata":{"id":"kUYI4UUHkRuV"},"source":["# 머신러닝 (Machine Learning)"]},{"cell_type":"markdown","metadata":{"id":"08zG1hh-kRuX"},"source":["## Kaggle 이미지 분류 대회 (Image Classification Competition)"]},{"cell_type":"markdown","metadata":{"id":"z5pz8NsTkRuX"},"source":["### 1. 데이터 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8GdRe8xkRuX"},"outputs":[],"source":["# 오늘은 Kaggle에서 데이터를 다운받고 이미지를 분류함으로써 대회에 참가하는 일련의 과정을 체험해 볼 예정입니다.\n","# 먼저 Kaggle에서 데이터를 다운받아 불러오도록 합시다.\n","\n","## 구글 드라이브 불러오기\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNRY9kbYkRuY"},"outputs":[],"source":["# 우리가 기존에 사용했던 MNIST나 CIFAR10 데이터 같은 경우, Pytorch에서 지원해주는 데이터를 사용했습니다.\n","# 그렇기에 이미 데이터가 전처리가 되어있었고, 우리가 추가로 전처리를 할 필요가 없었습니다.\n","# 하지만 이번에는 Real World 데이터를 다루는만큼, 데이터를 직접 데이터셋으로 바뀌는 과정을 진행하겠습니다.\n","\n","# 데이터를 데이터셋으로 변경하기 위해서는 클래스로 바꿔줄 필요가 있습니다.\n","# 이를 도와주는 라이브러리가 있는데요, 바로 torch.utils.data에 있는 Dataset 라이브러리입니다.\n","# torch.utils.data는 DataLoader와 random_split을 사용할 때 한번 보셨었는데 기억하실까요?\n","# 백문이 불여일견! 데이터셋으로 바꾸는 Class를 다같이 작성해봅시다.\n","\n","## csv 파일 처리를 위한 pandas 라이브러리 불러오기\n","import pandas as pd\n","\n","## Image 라이브러리 (이미지 처리) 불러오기\n","from PIL import Image\n","\n","## Dataset 라이브러리 불러오기 (겸사겸사 DataLoader와 random_split도 같이!)\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","## class 작성\n","class CustomDataset(Dataset):\n","    def __init__(self, img_dir, annotation_file=None, transforms=None, iter=None):\n","        self.data = []\n","        self.target = []\n","        self.transforms = transforms\n","        self.iter = iter\n","\n","        for path in img_dir:\n","            self.data.append(self.transforms(Image.open(path)))\n","\n","        if annotation_file:\n","            csv_file = pd.read_csv(annotation_file)\n","            self.target = csv_file['label']\n","\n","    def __len__(self):\n","        return len(self.target)\n","\n","    def __getitem__(self, idx):\n","        if self.iter:\n","            data = self.iter(self.data[idx])\n","        return data, self.target[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-F-6SWWhkRuY"},"outputs":[],"source":["# 먼저 데이터 경로를 저장해줍시다.\n","\n","train_path = \"\"\n","train_csv = \"\"\n","test_path = \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXrMYW3IkRuY"},"outputs":[],"source":["# 그 다음, 우리가 어떤 전처리를 할지 정해야겠죠? 전처리는 다음과 같이 진행하겠습니다.\n","# 일단 전처리를 하기 위해 transforms 라이브러리를 불러옵시다.\n","\n","from torchvision import transforms as T\n","\n","# 전처리는 다음과 같은 것을 해주겠습니다.\n","## T.Resize -> 이미지의 사이즈 변경\n","## T.RandomCrop -> 이미지를 랜덤하게 잘라냄\n","## T.RamdomHorizontalFlip -> 이미지를 랜덤하게 좌우반전 (Default: 0.5)\n","## T.ToTensor -> 이미지를 텐서(병렬계산이 가능하도록)로 변경\n","## T.Normalize -> 이미지의 학습이 빠르게 되도록 정규화\n","T = {\"train\": T.Compose([\n","        T.Resize((224,224)),\n","        T.ToTensor(),\n","        T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","        ]),\n","     \"iter\": T.Compose([\n","         T.RandomCrop(224, padding=4),\n","         T.RandomHorizontalFlip(),\n","     ])\n","    \"test\": T.Compose([\n","        T.Resize((224,224)),\n","        T.ToTensor(),\n","        T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","        ])\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2i9w8xokRuZ"},"outputs":[],"source":["# 이제 데이터를 불러올 준비가 모두 끝났습니다! 우리가 만든 class와 전처리를 이용하여 데이터를 불러옵시다.\n","\n","trainset = CustomDataset(train_path, train_csv, T['train'], T['iter'])\n","testset = CustomDataset(test_path, test_csv, T['test'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RPg81rk1kRuZ"},"outputs":[],"source":["# 자 이제 본격적인 학습에 앞서, torch 라이브러리를 불러옵시다.\n","import torch\n","\n","# 오늘도 시각화 툴을 이용하여 어떻게 생겼는지 확인해봅시다.\n","import matplotlib.pyplot as plt\n","\n","labels_map = {\n","    0: \"label 0\",\n","    1: \"label 1\"\n","}\n","figure = plt.figure(figsize=(10, 5))\n","cols, rows = 5, 2\n","for i in range(1, cols * rows + 1):\n","    sample_idx = torch.randint(len(trainset), size=(1,)).item()\n","    img, label = trainset[sample_idx]\n","    while label != i-1:\n","        sample_idx = torch.randint(len(trainset), size=(1,)).item()\n","        img, label = trainset[sample_idx]\n","    figure.add_subplot(rows, cols, i)\n","    plt.title(labels_map[label])\n","    plt.axis(\"off\")\n","    plt.imshow(img.permute(1, 2, 0))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"S850e-vZkRuZ"},"source":["### 2. 데이터 분할 (Train/Valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0yfdJYykRuZ"},"outputs":[],"source":["# 여기까지 따라오시느라 고생했습니다! 이 아래는 이제 비슷해요\n","# 우리가 늘 했던 것처럼 데이터셋의 1할은 제대로 학습이 되는지 확인을 할 목적으로 나눠줍시다.\n","# 이를 위해서는 먼저, seed를 고정해주도록 합시다!\n","\n","## seed 고정\n","def seed_fix(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","\n","seed_fix(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phy9aO4nkRuZ"},"outputs":[],"source":["# train 데이터의 이미지 개수를 우선 확인합니다.\n","train_size = len(trainset)\n","print(train_size)\n","\n","# 분할은 늘 하던대로, 9:1로 진행합시다.\n","val_ratio = 0.1\n","\n","## validation으로 사용할 데이터의 수 확인\n","split = int(train_size*val_ratio)\n","\n","## 데이터 분할; random_split(데이터셋, [train 데이터의 수, validation 데이터의 수])\n","train_dataset, val_dataset = random_split(trainset, [train_size-split, split])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZO_4L8t-kRuZ"},"outputs":[],"source":["# 저번 시간에 배웠던대로 DataLoader를 사용해봅시다.\n","# DataLoader가 기억이 안나신다면 망설이지 말고 질문주세요!\n","\n","## train, validation, test dataloader로 변환\n","train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_dataloader = DataLoader(testset, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"uvNd1VpckRua"},"source":["### 3. 모델 아키텍쳐 설계"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaHLphdokRua"},"outputs":[],"source":["# 우리가 저번 시간에 했던 것처럼 모델을 설계해봅시다.\n","# 오늘은 저번에 제가 잠깐 언급 드렸던 모델인 Alexnet(2014)을 설계해볼거에요\n","\n","## nn 라이브러리 불러오기\n","import torch.nn as nn\n","\n","class AlexNet(nn.Module):\n","    def __init__(self):\n","        super(AlexNet, self).__init__()\n","        self.Convolutional = nn.Sequential(\n","            nn.Conv2d(in_channels=3,\n","                      out_channels=96,\n","                      kernel_size=11,\n","                      stride=4,\n","                      padding=0),\n","            nn.BatchNorm2d(96),\n","            nn.ReLU(),\n","            nn.MaxPool2d(3, 2),\n","\n","            nn.Conv2d(in_channels=96,\n","                      out_channels=256,\n","                      kernel_size=5,\n","                      stride=1,\n","                      padding=2),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(3, 2),\n","\n","            nn.Conv2d(in_channels=256,\n","                      out_channels=384,\n","                      kernel_size=3,\n","                      stride=1,\n","                      padding=1),\n","            nn.BatchNorm2d(384),\n","            nn.ReLU(),\n","\n","            nn.Conv2d(in_channels=384,\n","                      out_channels=384,\n","                      kernel_size=3,\n","                      stride=1,\n","                      padding=1),\n","            nn.BatchNorm2d(384),\n","            nn.ReLU(),\n","\n","            nn.Conv2d(in_channels=384,\n","                      out_channels=256,\n","                      kernel_size=3,\n","                      stride=1,\n","                      padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(3, 2),\n","        )\n","        self.fullyconnected = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(256*6*6, 4096),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(),\n","            nn.Linear(4096, 11),\n","        )\n","\n","    def forward(self, x):\n","        x = self.Convolutional(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fullyconnected(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"36JJ561AkRua"},"source":["### 4. Train/Evaluation code 작성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ATieNW3ZkRua"},"outputs":[],"source":["def train(model, dataloader, optim, criterion, device):\n","    model.train()\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    train_loss, train_acc = 0, 0\n","\n","    for idx, (data, target) in enumerate(dataloader):\n","        data, target = data.to(device), target.to(device)\n","        pred = model(data)\n","        loss = criterion(pred, target)\n","\n","        loss.backward()\n","        optim.step()\n","        optim.zero_grad()\n","\n","        train_loss += loss.item()\n","        train_acc += (pred.argmax(1) == target).type(torch.float).sum().item()\n","\n","    train_loss /= num_batches\n","    train_acc /= size\n","\n","    print(f\"Train: \\n Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f}\")\n","\n","def evaluation(model, dataloader, device, test=False):\n","    model.eval()\n","    size = len(dataloader.dataset)\n","    validation_acc = 0\n","\n","    with torch.no_grad():\n","        for data, target in dataloader:\n","            data, target = data.to(device), target.to(device)\n","            pred = model(data)\n","\n","            validation_acc += (pred.argmax(1) == target).type(torch.float).sum().item()\n","\n","    validation_acc /= size\n","\n","    print(f\"Validation: \\n Accuracy: {(100*validation_acc):>0.1f}%\\n\")\n","\n","    return validation_acc"]},{"cell_type":"markdown","metadata":{"id":"gsl02tzykRua"},"source":["### 5. 모델 훈련 및 성능 확인"]},{"cell_type":"markdown","metadata":{"id":"7M_4-aOKkRua"},"source":["#### 5-1. CUDA 연결"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hI3L5QUmkRua","outputId":"3c9a8dc1-3bc1-46fe-a742-520de516ee05"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"0DlIPA-qkRub"},"source":["#### 5-2. 학습 진행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_A8sC-m7kRub"},"outputs":[],"source":["## 모델 저장을 위한 라이브러리\n","import copy\n","\n","# 우리가 만든 모델을 불러옵시다.\n","model = AlexNet().to(device)\n","\n","# 또, 결과가 가장 좋았던 모델을 저장하기위해 가장 좋은 결과를 저장하는 변수와 모델을 저장하는 변수를 하나씩 만듭시다.\n","best_model = None\n","best_val_acc = 0\n","\n","# loss를 계산하는 방식은 CrossEntropyLoss를 사용합시다.\n","criterion = nn.CrossEntropyLoss()\n","\n","# 또한, 가중치를 업데이트하는 방식은 Adam을 사용합시다.\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# 가볍게 10번 정도 학습해봅시다. epoch는 반복횟수를 의미하는 단어입니다.\n","epochs = 10\n","print(f\"Training Starts ...\\n{model} || {criterion} || {optimizer} || CIFAR10\")\n","for epoch in range(epochs):\n","    print(f'Epoch {epoch+1} >>>')\n","    train(model, train_dataloader, optimizer, criterion, device)\n","    val_acc = evaluation(model, val_dataloader, device)\n","    if val_acc > best_val_acc:\n","        best_model = copy.deepcopy(model)"]},{"cell_type":"markdown","metadata":{"id":"lTAw5T1GkRub"},"source":["#### 5-3. Test 성능 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1DowudzLkRub"},"outputs":[],"source":["# 자 여기에서 우리가 지금까지 해온 부분과 Kaggle 대회의 차이점이 생깁니다.\n","# Kaggle의 경우 Test의 정답이 제공되지 않기 때문에, Test image를 분류한 결과를 저장하고, 이를 제출하여 정확도를 확인합니다.\n","# 따라서 우리도 Test용 Evaluation code를 새로 작성하여 정답을 제출해봅시다.\n","\n","def evaluation_test(model, test_dataloader):\n","    pred = None\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for X, _ in test_dataloader:\n","            X = X.to(device)\n","            Y = model(X)\n","            if pred == None:\n","                pred = Y.argmax(1)\n","            else:\n","                pred = torch.cat((pred, Y.argmax(1)), dim=0)\n","\n","    return pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vauX-b3LkRuc"},"outputs":[],"source":["# 위에서 우리가 작성한 코드를 기반으로 Test의 정답 label을 예측해봅시다.\n","# 예측을 진행한 후에는, 정답을 csv로 저장하여 kaggle 사이트에 제출하면 됩니다!\n","\n","## Test 결과 예측\n","pred = evaluation_test(best_model, test_dataloader, device)\n","\n","## 정답 pandas로 변경\n","test_pred = pd.DataFrame([i for i in range(len(pred))], columns=[\"file_name\"])\n","test_pred['label'] = test_pred.to(\"cpu\").numpy()\n","test_pred.tail()\n","\n","## 정답 저장\n","test_pred.to_csv('./Kaggle_pred.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"ebyESWhBkRuc"},"source":["이제 여러분은 Kaggle이나 Dacon과 같은 대회에 참가할 수 있는 충분한 실력이 되었습니다!<br><br>\n","여기서 우리는 1. 모델의 구조를 바꾸거나, 2. epoch의 수를 늘리거나, 3. transforms를 이용한 이미지 전처리를 이용하여 정확도를 올릴 수 있습니다.<br><br>\n","한 학기동안 부족한 강의 들어주셔서 감사드리며, 앞으로 여러분들께 좋은 일만 있으시길 기원하겠습니다! 감사합니다"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.11"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}